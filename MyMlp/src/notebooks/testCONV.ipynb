{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ab3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../MyReverseDiff.jl\")\n",
    "include(\"../MyEmbedding.jl\")\n",
    "include(\"../MyMlp.jl\")\n",
    "\n",
    "using .MyReverseDiff\n",
    "using .MyMlp\n",
    "using JLD2\n",
    "using Printf\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74424a3",
   "metadata": {},
   "source": [
    "## Przygotowanie danych IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a09dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = load(\"../../dataset/imdb_dataset_prepared.jld2\", \"X_train\");\n",
    "y_train = load(\"../../dataset/imdb_dataset_prepared.jld2\", \"y_train\");\n",
    "X_test = load(\"../../dataset/imdb_dataset_prepared.jld2\", \"X_test\");\n",
    "y_test = load(\"../../dataset/imdb_dataset_prepared.jld2\", \"y_test\");\n",
    "embeddings = load(\"../../dataset/imdb_dataset_prepared.jld2\", \"embeddings\")\n",
    "# vocab = load(\"../../dataset/imdb_dataset_prepared.jld2\", \"vocab\");\n",
    "\n",
    "input_size = size(X_train, 1) # Liczba cech\n",
    "embedding_dim = size(embeddings, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e89f70",
   "metadata": {},
   "source": [
    "##  Trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb6a008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model = Chain(\n",
    "    Embedding(embeddings, name=\"embedding\"),\n",
    "    TransposeBlock(),\n",
    "    ConvolutionBlock(3,50,8, name=\"layer1\"),\n",
    "    PoolingBlock(8),\n",
    "    FlattenBlock(name=\"flatten\"),\n",
    "    Dense(input_size-2, 1, σ, name=\"softnet\")\n",
    ")\n",
    "\n",
    "#   Utworzenie początkowych węzłów Constant dla danych wejściowych i etykiet\n",
    "x_input_node = Constant(zeros(Float32, input_size, batch_size))\n",
    "y_label_node = Constant(zeros(Float32, 1, batch_size))\n",
    "\n",
    "#   Budowanie grafu treningowego\n",
    "loss_node, model_output_node, order = build_graph!(model, binarycrossentropy, x_input_node, y_label_node; loss_name=\"loss\")\n",
    "\n",
    "optimizer_state = setup_optimizer(Adam(a=0.001f0), model)\n",
    "\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc20ef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Rozpoczynam profilowanie treningu ---\n",
      "\n",
      "Epoch: 1\n",
      "Epoch: 1 \tTrain: (l: 0.6439) \tTotal Batch Time: 75.0773s \tTotal Alloc: 45.688 GiB \tGC Time: 12.7413s\n",
      "\n",
      "Epoch: 2\n",
      "Epoch: 2 \tTrain: (l: 0.5172) \tTotal Batch Time: 51.7651s \tTotal Alloc: 44.498 GiB \tGC Time: 10.5508s\n",
      "\n",
      "Epoch: 3\n",
      "Epoch: 3 \tTrain: (l: 0.4742) \tTotal Batch Time: 53.9560s \tTotal Alloc: 44.498 GiB \tGC Time: 11.3143s\n",
      "\n",
      "Epoch: 4\n",
      "Epoch: 4 \tTrain: (l: 0.4509) \tTotal Batch Time: 53.6382s \tTotal Alloc: 44.498 GiB \tGC Time: 11.1779s\n",
      "\n",
      "Epoch: 5\n",
      "Epoch: 5 \tTrain: (l: 0.4366) \tTotal Batch Time: 53.9492s \tTotal Alloc: 44.498 GiB \tGC Time: 11.3131s\n",
      "\n",
      "--- Koniec profilowania treningu ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(\"--- Rozpoczynam profilowanie treningu ---\")\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    permutation = randperm(size(X_train, 2))\n",
    "    X_train_shuffled_epoch = X_train[:, permutation]\n",
    "    y_train_shuffled_epoch = y_train[:, permutation]\n",
    "    num_batches = ceil(Int, size(X_train, 2) / batch_size)\n",
    "\n",
    "    loss_value = 0.0\n",
    "\n",
    "    println(\"\\nEpoch: $epoch\")\n",
    "    total_batch_time = 0.0\n",
    "    total_batch_alloc = 0\n",
    "    total_batch_gc_time = 0.0\n",
    "\n",
    "    for i in 1:num_batches\n",
    "        start_idx = (i - 1) * batch_size + 1\n",
    "        end_idx = min(i * batch_size, size(X_train, 2))\n",
    "        x_batch_view = view(X_train_shuffled_epoch, :, start_idx:end_idx)\n",
    "        y_batch_view = view(y_train_shuffled_epoch, :, start_idx:end_idx)\n",
    "\n",
    "        current_batch_size = size(x_batch_view, 2)\n",
    "        view(x_input_node.output, :, 1:current_batch_size) .= x_batch_view\n",
    "        view(y_label_node.output, :, 1:current_batch_size) .= y_batch_view\n",
    "\n",
    "        stats = @timed begin # `timed` zwraca strukturę z wynikami, `time` tylko czas\n",
    "            forward!(order)\n",
    "            backward!(order)\n",
    "            step!(optimizer_state) # Zakładam, że masz już zaimplementowane step!\n",
    "        end\n",
    "        loss_value += loss_node.output # Upewnij się, że loss_node.output jest odświeżane po forward\n",
    "\n",
    "        total_batch_time += stats.time\n",
    "        total_batch_alloc += stats.bytes\n",
    "        total_batch_gc_time += stats.gctime\n",
    "    end\n",
    "\n",
    "    avg_loss_epoch = loss_value / num_batches\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d \\tTrain: (l: %.4f) \\tTotal Batch Time: %.4fs \\tTotal Alloc: %s \\tGC Time: %.4fs\",\n",
    "        epoch, avg_loss_epoch, total_batch_time, Base.format_bytes(total_batch_alloc), total_batch_gc_time))\n",
    "end\n",
    "\n",
    "println(\"\\n--- Koniec profilowania treningu ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122bc3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (czas: 3.45s): 0.4353\n",
      "Test Accuracy: 80.55 %\n"
     ]
    }
   ],
   "source": [
    "# --- Test Evaluation ---\n",
    "\n",
    "batch_size = 64\n",
    "num_test_samples = size(X_test, 2)\n",
    "num_batches = ceil(Int, num_test_samples / batch_size)\n",
    "total_test_loss_sum = 0.0\n",
    "total_correct_predictions = 0.0\n",
    "\n",
    "t_test = @elapsed begin\n",
    "    for i in 1:num_batches\n",
    "\n",
    "        start_idx = (i - 1) * batch_size + 1\n",
    "        end_idx = min(i * batch_size, num_test_samples)\n",
    "        x_batch_test = X_test[:, start_idx:end_idx]\n",
    "        y_batch_test = y_test[:, start_idx:end_idx]\n",
    "\n",
    "        # Aktualna liczba próbek w bieżącym batchu (może być mniejsza dla ostatniego batcha)\n",
    "        current_test_batch_size = size(x_batch_test, 2)\n",
    "\n",
    "        view(x_input_node.output, :, 1:current_test_batch_size) .= x_batch_test\n",
    "        view(y_label_node.output, :, 1:current_test_batch_size) .= y_batch_test\n",
    "\n",
    "        forward!(order)\n",
    "\n",
    "        predictions = view(model_output_node.output, :, 1:current_test_batch_size)\n",
    "\n",
    "\n",
    "        batch_loss = loss_node.output\n",
    "\n",
    "        total_test_loss_sum += batch_loss * current_test_batch_size # Sumuj stratę, uwzględniając rozmiar batcha\n",
    "\n",
    "        # --- Oblicz dokładność na bieżącym batchu testowym ---\n",
    "        # Dla klasyfikacji binarnej z progiem 0.5 (lub innym, w zależności od problemu)\n",
    "        batch_accuracy = sum((predictions .> 0.5f0) .== y_batch_test) / current_test_batch_size\n",
    "        total_correct_predictions += batch_accuracy * current_test_batch_size # Sumuj poprawne predykcje\n",
    "    end\n",
    "end\n",
    "\n",
    "# --- Oblicz średnią stratę i średnią dokładność na całym zbiorze testowym ---\n",
    "avg_test_loss = total_test_loss_sum / num_test_samples\n",
    "avg_test_accuracy = total_correct_predictions / num_test_samples * 100.0\n",
    "\n",
    "println(@sprintf(\"Test Loss (czas: %.2fs): %.4f\", t_test, avg_test_loss))\n",
    "println(\"Test Accuracy: $avg_test_accuracy %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
