{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f1ba62",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3221369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m      Compat\u001b[22m\u001b[39m entries added for \n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Repos/AWiD/MyMlp/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Repos/AWiD/MyMlp/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Repos/AWiD/MyMlp`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mProject\u001b[22m\u001b[39m MyMlp v0.1.0\n",
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Repos/AWiD/MyMlp/Project.toml`\n",
      "  \u001b[90m[6e4b80f9] \u001b[39mBenchmarkTools v1.6.0\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're using the latest version\n",
    "import Pkg\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "Pkg.activate(\"../..\")  # Activate the project environment\n",
    "Pkg.instantiate()      # Install any missing dependencies\n",
    "Pkg.status()          # Check if MyMlp is listed\n",
    "\n",
    "# Now try importing\n",
    "using BenchmarkTools\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb89e6c",
   "metadata": {},
   "source": [
    "## Comparison of different optimizations to Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8f4feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Benchmark: READ access ###\n",
      "Original:\n",
      "  14.034 ns (1 allocation: 16 bytes)\n",
      "Optimized:\n",
      "  1.575 ns (0 allocations: 0 bytes)\n",
      "RefValue:\n",
      "  1.793 ns (0 allocations: 0 bytes)\n",
      "\n",
      "### Benchmark: WRITE mutation ###\n",
      "Original:\n",
      "  14.417 ns (1 allocation: 16 bytes)\n",
      "Optimized:\n",
      "  2.013 ns (0 allocations: 0 bytes)\n",
      "RefValue:\n",
      "  2.013 ns (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500503.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "using BenchmarkTools\n",
    "\n",
    "abstract type GraphNode end\n",
    "abstract type Operator <: GraphNode end\n",
    "\n",
    "# Original implementation\n",
    "mutable struct VariableOriginal <: GraphNode\n",
    "    output :: Any\n",
    "    grad :: Any\n",
    "    name :: String\n",
    "    VariableOriginal(output; name=\"?\") = new(output, nothing, name)\n",
    "end\n",
    "\n",
    "# Optimized implementation\n",
    "mutable struct VariableOptimized{T<:Float64} <: GraphNode\n",
    "    output :: T\n",
    "    grad :: Union{Nothing, T}\n",
    "    name :: String\n",
    "    VariableOptimized(output::T; name=\"?\") where T<:Float64 = new{T}(output, nothing, name)\n",
    "end\n",
    "\n",
    "# RefValue-based immutable implementation\n",
    "struct VariableRef <: GraphNode\n",
    "    output :: Base.RefValue{Float64}\n",
    "    grad   :: Union{Nothing, Base.RefValue{Float64}}\n",
    "    name   :: String\n",
    "    function VariableRef(output::Float64; name=\"?\")\n",
    "        new(Base.RefValue(output), nothing, name)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Functions to benchmark: reading\n",
    "function read_output(v::VariableOriginal)\n",
    "    v.output + 1.0\n",
    "end\n",
    "\n",
    "function read_output(v::VariableOptimized)\n",
    "    v.output + 1.0\n",
    "end\n",
    "\n",
    "function read_output(v::VariableRef)\n",
    "    v.output[] + 1.0\n",
    "end\n",
    "\n",
    "# Functions to benchmark: writing\n",
    "function write_output!(v::VariableOriginal)\n",
    "    v.output = v.output + 1.0\n",
    "end\n",
    "\n",
    "function write_output!(v::VariableOptimized)\n",
    "    v.output = v.output + 1.0\n",
    "end\n",
    "\n",
    "function write_output!(v::VariableRef)\n",
    "    v.output[] = v.output[] + 1.0\n",
    "end\n",
    "\n",
    "# Create instances\n",
    "v1 = VariableOriginal(1.0)\n",
    "v2 = VariableOptimized(1.0)\n",
    "v3 = VariableRef(1.0)\n",
    "\n",
    "# Benchmark READ\n",
    "println(\"### Benchmark: READ access ###\")\n",
    "println(\"Original:\")\n",
    "@btime read_output($v1)\n",
    "\n",
    "println(\"Optimized:\")\n",
    "@btime read_output($v2)\n",
    "\n",
    "println(\"RefValue:\")\n",
    "@btime read_output($v3)\n",
    "\n",
    "# Benchmark WRITE\n",
    "println(\"\\n### Benchmark: WRITE mutation ###\")\n",
    "println(\"Original:\")\n",
    "@btime write_output!($v1)\n",
    "\n",
    "println(\"Optimized:\")\n",
    "@btime write_output!($v2)\n",
    "\n",
    "println(\"RefValue:\")\n",
    "@btime write_output!($v3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694cbbe",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212c68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 5 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: *, +\n",
    "import LinearAlgebra: mul!\n",
    "\n",
    "abstract type GraphNode end\n",
    "abstract type Operator <: GraphNode end\n",
    "\n",
    "# Definition of basic structures for computational graph\n",
    "struct Constant{T<:Float64} <: GraphNode\n",
    "    output :: T\n",
    "end\n",
    "\n",
    "mutable struct Variable <: GraphNode\n",
    "    output :: Matrix{Float64}\n",
    "    gradient :: Union{Nothing, Matrix{Float64}}\n",
    "    name :: String\n",
    "    Variable(output::Matrix{Float64}; name=\"?\") = new(output, nothing, name)\n",
    "end\n",
    "\n",
    "mutable struct ScalarOperator{F} <: Operator\n",
    "    inputs :: Union{Nothing, Tuple{GraphNode, GraphNode}}\n",
    "    output :: Union{Nothing, Float64}\n",
    "    gradient :: Union{Nothing, Float64}\n",
    "    name :: String\n",
    "    ScalarOperator(fun, inputs...; name=\"?\") = new{typeof(fun)}(inputs, nothing, nothing, name)\n",
    "end\n",
    "\n",
    "mutable struct BroadcastedOperator{F} <: Operator\n",
    "    inputs :: Union{Nothing, Tuple{GraphNode, GraphNode}, Tuple{GraphNode}}\n",
    "    output :: Union{Nothing, Matrix{Float64}}\n",
    "    gradient :: Union{Nothing, Matrix{Float64}}\n",
    "    name :: String\n",
    "    BroadcastedOperator(fun, inputs...; name=\"?\") = new{typeof(fun)}(inputs, nothing, nothing, name)\n",
    "end\n",
    "\n",
    "\n",
    "import Base: show, summary\n",
    "show(io::IO, x::ScalarOperator{F}) where {F} = print(io, \"op \", x.name, \"(\", F, \")\");\n",
    "show(io::IO, x::BroadcastedOperator{F}) where {F} = print(io, \"op.\", x.name, \"(\", F, \")\");\n",
    "show(io::IO, x::Constant) = print(io, \"const \", x.output)\n",
    "show(io::IO, x::Variable) = begin\n",
    "    print(io, \"var \", x.name);\n",
    "    print(io, \"\\n ┣━ ^ \"); summary(io, x.output)\n",
    "    print(io, \"\\n ┗━ ∇ \");  summary(io, x.gradient)\n",
    "end\n",
    "\n",
    "\n",
    "function visit(node::GraphNode, visited, order)\n",
    "    if node ∈ visited\n",
    "    else\n",
    "        push!(visited, node)\n",
    "        push!(order, node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function visit(node::Operator, visited, order)\n",
    "    if node ∈ visited\n",
    "    else\n",
    "        push!(visited, node)\n",
    "        for input in node.inputs\n",
    "            visit(input, visited, order)\n",
    "        end\n",
    "        push!(order, node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function topological_sort(head::GraphNode)\n",
    "    visited = Set()\n",
    "    order = Vector()\n",
    "    visit(head, visited, order)\n",
    "    return order\n",
    "end\n",
    "\n",
    "\n",
    "# x * y (aka matrix multiplication)\n",
    "*(A::GraphNode, x::GraphNode) = BroadcastedOperator(mul!, A, x)\n",
    "forward(::BroadcastedOperator{typeof(mul!)}, A, x) = return A * x\n",
    "backward(::BroadcastedOperator{typeof(mul!)}, A, x, g) = tuple(g * x', A' * g)\n",
    "\n",
    "# relu activation\n",
    "relu(x::GraphNode) = BroadcastedOperator(relu, x)\n",
    "forward(::BroadcastedOperator{typeof(relu)}, x) = return x .* (x .> 0.0)\n",
    "backward(::BroadcastedOperator{typeof(relu)}, x, g) = tuple(g .* (x .> 0.0), nothing)\n",
    "\n",
    "# add operation (for bias)\n",
    "+(x::GraphNode, y::GraphNode) = BroadcastedOperator(+, x, y)\n",
    "forward(::BroadcastedOperator{typeof(+)}, x, y) = return x .+ y\n",
    "backward(::BroadcastedOperator{typeof(+)}, x, y, g) = tuple(g, g)\n",
    "\n",
    "# sigmoid activation\n",
    "σ(x::GraphNode) = BroadcastedOperator(σ, x)\n",
    "forward(::BroadcastedOperator{typeof(σ)}, x) = return 1.0 ./ (1.0 .+ exp.(-x))\n",
    "backward(node::BroadcastedOperator{typeof(σ)}, x, g) = let\n",
    "    y = node.output\n",
    "    # vec() przeksztalca macierz w wektor, wymagane do dzialania\n",
    "    J = diagm(vec(y .* (1.0 .- y)))\n",
    "    tuple(J' * g)\n",
    "end\n",
    "\n",
    "# binarycrossentropy\n",
    "binarycrossentropy(y::GraphNode, ŷ::GraphNode) = ScalarOperator(binarycrossentropy, y, ŷ)\n",
    "forward(::ScalarOperator{typeof(binarycrossentropy)}, ŷ, y) = begin\n",
    "    return -mean(y .* log.(ŷ) + (1.0 .- y) .* log.(1.0 .- ŷ))\n",
    "end\n",
    "backward(::ScalarOperator{typeof(binarycrossentropy)}, ŷ, y, g) = begin\n",
    "    J = (ŷ .- y) ./ (ŷ .* (1.0 .- ŷ))\n",
    "    return (J * g, nothing)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f27fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reset!(node::Constant) = nothing\n",
    "\n",
    "reset!(node::Variable) = node.gradient = nothing\n",
    "reset!(node::Operator) = node.gradient = nothing\n",
    "\n",
    "compute!(node::Constant) = nothing\n",
    "compute!(node::Variable) = nothing\n",
    "\n",
    "compute!(node::Operator) =\n",
    "    node.output = forward(node, [input.output for input in node.inputs]...)\n",
    "\n",
    "function forward!(order::Vector)\n",
    "    #   Iteruje przez każdy węzeł w order.\n",
    "    for node in order\n",
    "        compute!(node)\n",
    "        reset!(node)\n",
    "    end\n",
    "    return last(order).output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c495933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward! (generic function with 4 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update!(node::Constant, gradient) = nothing\n",
    "\n",
    "update!(node::GraphNode, gradient) = if isnothing(node.gradient)\n",
    "    node.gradient = gradient else node.gradient .+= gradient\n",
    "end\n",
    "\n",
    "\n",
    "function backward!(order::Vector; seed=1.0)\n",
    "    result = last(order)   #   The output node\n",
    "\n",
    "    if isa(result.output, Matrix{Float64})\n",
    "        result.gradient = ones(Float64, size(result.output))\n",
    "    else\n",
    "        result.gradient = seed\n",
    "        @assert length(result.output) == 1 \"Gradient is defined only for scalar functions\"\n",
    "    end\n",
    "\n",
    "    for node in reverse(order)   #   Iterate through nodes in reverse topological order.\n",
    "        backward!(node)   #   Compute and propagate gradients backwards.\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function backward!(node::Constant) end\n",
    "function backward!(node::Variable) end\n",
    "\n",
    "function backward!(node::Operator)\n",
    "    inputs = node.inputs\n",
    "\n",
    "    gradients = backward(node, [input.output for input in inputs]..., node.gradient)\n",
    "\n",
    "    for (input, gradient) in zip(inputs, gradients)\n",
    "        update!(input, gradient)\n",
    "    end\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686905b",
   "metadata": {},
   "source": [
    "## Test wejścia do neuronu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c1d7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var x\n",
       " ┣━ ^ 3×1 Matrix{Float64}\n",
       " ┗━ ∇ Nothing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = Variable(reshape([1.0, 2.0, 3.0], 3, 1), name=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb994942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var w\n",
       " ┣━ ^ 1×3 Matrix{Float64}\n",
       " ┗━ ∇ Nothing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = Variable(reshape([1.0, 2.0, 3.0], 1, 3), name=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e83b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"z\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = w * x\n",
    "z.name = \"z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6fc88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topological order:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Vector{Any}:\n",
       " var w\n",
       " ┣━ ^ 1×3 Matrix{Float64}\n",
       " ┗━ ∇ Nothing\n",
       " var x\n",
       " ┣━ ^ 3×1 Matrix{Float64}\n",
       " ┗━ ∇ Nothing\n",
       " op.z(typeof(mul!))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "order = topological_sort(z)\n",
    "println(\"Topological order:\")\n",
    "order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63689cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Matrix{Float64}:\n",
       " 14.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = forward!(order)\n",
    "z.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6544db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×3 Matrix{Float64}:\n",
       " 1.0  2.0  3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backward!(order)\n",
    "w.gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7746c8e",
   "metadata": {},
   "source": [
    "## Test 2 szeregowych Neuronów - 1 warstwa + bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca98db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(reshape([1.0, 2.0, 3.0], 3, 1), name=\"x\")\n",
    "w = Variable(reshape([-2.0, 3.0, -4.0, 5.0, -6.0, 7.0], 2, 3), name=\"w\")\n",
    "z = w * x\n",
    "z.name = \"z\"\n",
    "c = Constant(1.0)\n",
    "d = z + c\n",
    "# dense_layer_2 = σ(z)\n",
    "# dense_layer_2.name = \"σ(z)\"\n",
    "dense_layer_2 = relu(d)\n",
    "dense_layer_2.name = \"relu(d)\"\n",
    "order = topological_sort(dense_layer_2)\n",
    "y = forward!(order)\n",
    "backward!(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34a9a0",
   "metadata": {},
   "source": [
    "## Test 2. warstw neuronów 2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Vector{Any}:\n",
       " var w2\n",
       " ┣━ ^ 4×2 Matrix{Float64}\n",
       " ┗━ ∇ Nothing\n",
       " var w1\n",
       " ┣━ ^ 2×3 Matrix{Float64}\n",
       " ┗━ ∇ Nothing\n",
       " var x\n",
       " ┣━ ^ 3×1 Matrix{Float64}\n",
       " ┗━ ∇ Nothing\n",
       " op.a(typeof(mul!))\n",
       " op.b(typeof(relu))\n",
       " op.c(typeof(mul!))\n",
       " op.d(typeof(relu))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#   Pierwsza warstwa\n",
    "x = Variable(reshape([1.0, 2.0, 3.0], 3, 1), name=\"x\")\n",
    "w = Variable(reshape([2.0, 3.0, 4.0, 5.0, 6.0, 7.0], 2, 3), name=\"w1\")\n",
    "a = w * x\n",
    "a.name = \"a\"\n",
    "b = relu(a)\n",
    "b.name = \"b\"\n",
    "\n",
    "#   Druga warstwa\n",
    "w2 = Variable(reshape([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0], 4,2), name=\"w2\")\n",
    "c = w2 * b\n",
    "c.name = \"c\"\n",
    "d = relu(c)\n",
    "d.name = \"d\"\n",
    "order = topological_sort(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8583b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = forward!(order)\n",
    "backward!(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4798c5",
   "metadata": {},
   "source": [
    "## Test binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce454e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2231435513142097"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ŷ = Variable(reshape([0.8], 1, 1), name=\"ŷ\")\n",
    "y = Variable(reshape([1.0], 1, 1), name=\"y\")\n",
    "loss = binarycrossentropy(ŷ, y)\n",
    "loss.name = \"loss\"\n",
    "order = topological_sort(loss)\n",
    "result = forward!(order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2daa76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward!(order)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
