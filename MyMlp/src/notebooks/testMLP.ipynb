{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e231298",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../MyReverseDiff.jl\")\n",
    "include(\"../MyMlp.jl\")\n",
    "\n",
    "using .MyReverseDiff\n",
    "using .MyMlp\n",
    "using JLD2\n",
    "using Printf\n",
    "using BenchmarkTools\n",
    "using LinearAlgebra\n",
    "using Distributions\n",
    "using Random\n",
    "using MLDatasets\n",
    "using Plots\n",
    "using Statistics\n",
    "using DataFrames\n",
    "using MLDataUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37288ea0",
   "metadata": {},
   "source": [
    "## Przygotowanie danych IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaed8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Matrix(load(\"../../dataset/imdb_dataset_prepared.jld2\", \"X_train\"));\n",
    "y_train = Matrix(load(\"../../dataset/imdb_dataset_prepared.jld2\", \"y_train\"));\n",
    "X_test = Matrix(load(\"../../dataset/imdb_dataset_prepared.jld2\", \"X_test\"));\n",
    "y_test = Matrix(load(\"../../dataset/imdb_dataset_prepared.jld2\", \"y_test\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a6521",
   "metadata": {},
   "source": [
    "##  Trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb93cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (6.38s) \tTrain: (l: 0.67)\n",
      "Epoch: 2 (1.33s) \tTrain: (l: 0.58)\n",
      "Epoch: 3 (1.33s) \tTrain: (l: 0.47)\n",
      "Epoch: 4 (1.30s) \tTrain: (l: 0.37)\n",
      "Epoch: 5 (1.31s) \tTrain: (l: 0.30)\n"
     ]
    }
   ],
   "source": [
    "#   Definicja rozmiarów modelu\n",
    "input_size = size(X_train, 1) # Liczba cech\n",
    "hidden_size = 8\n",
    "output_size = 1\n",
    "batch_size = 64\n",
    "\n",
    "#   Inicjalizacja modelu (Chain) (raz)\n",
    "model = Chain(\n",
    "    Dense(input_size, hidden_size, relu; weight_init=xavier_uniform,  name=\"layer1\"),\n",
    "    Dense(hidden_size, output_size, σ; weight_init=xavier_uniform, name=\"layer2\")\n",
    ")\n",
    "\n",
    "#   Utworzenie początkowych węzłów Constant dla danych wejściowych i etykiet\n",
    "x_input_node = Constant(zeros(Float32, input_size, batch_size))\n",
    "y_label_node = Constant(zeros(Float32, output_size, batch_size))\n",
    "\n",
    "#   Budowanie grafu treningowego\n",
    "loss_node, model_output_node, order = build_graph!(model, binarycrossentropy, x_input_node, y_label_node; loss_name=\"loss\")\n",
    "\n",
    "optimizer_state = setup_optimizer(Adam(), model)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    # --- Tasowanie zbioru treningowego NA NOWO w każdej epoce ---\n",
    "    permutation = randperm(size(X_train, 2))\n",
    "    X_train_shuffled_epoch = X_train[:, permutation]\n",
    "    y_train_shuffled_epoch = y_train[:, permutation]\n",
    "    num_batches = ceil(Int, size(X_train, 2) / batch_size)\n",
    "\n",
    "    loss_value = 0.0\n",
    "\n",
    "    t = @elapsed begin\n",
    "\n",
    "    for i in 1:num_batches\n",
    "\n",
    "        start_idx = (i - 1) * batch_size + 1\n",
    "        end_idx = min(i * batch_size, size(X_train, 2))\n",
    "        x_batch = X_train_shuffled_epoch[:, start_idx:end_idx]\n",
    "        y_batch = y_train_shuffled_epoch[:, start_idx:end_idx]\n",
    "\n",
    "        current_batch_size = size(x_batch, 2)\n",
    "        view(x_input_node.output, :, 1:current_batch_size) .= x_batch\n",
    "        view(y_label_node.output, :, 1:current_batch_size) .= y_batch\n",
    "\n",
    "\n",
    "        forward!(order)\n",
    "\n",
    "        backward!(order)\n",
    "\n",
    "        step!(optimizer_state)\n",
    "        loss_value += loss_node.output\n",
    "\n",
    "    end\n",
    "end\n",
    "    avg_loss_epoch = loss_value / num_batches\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f)\", epoch, t, avg_loss_epoch))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ef078",
   "metadata": {},
   "source": [
    "##  Test modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f308f319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (czas: 0.38s): 0.3883\n",
      "Test Accuracy: 86.1 %\n"
     ]
    }
   ],
   "source": [
    "# --- Test Evaluation ---\n",
    "\n",
    "batch_size = 64\n",
    "num_test_samples = size(X_test, 2)\n",
    "num_batches = ceil(Int, num_test_samples / batch_size)\n",
    "total_test_loss_sum = 0.0\n",
    "total_correct_predictions = 0.0\n",
    "\n",
    "t_test = @elapsed begin\n",
    "    for i in 1:num_batches\n",
    "\n",
    "        start_idx = (i - 1) * batch_size + 1\n",
    "        end_idx = min(i * batch_size, num_test_samples)\n",
    "        x_batch_test = X_test[:, start_idx:end_idx]\n",
    "        y_batch_test = y_test[:, start_idx:end_idx]\n",
    "\n",
    "        # Aktualna liczba próbek w bieżącym batchu (może być mniejsza dla ostatniego batcha)\n",
    "        current_test_batch_size = size(x_batch_test, 2)\n",
    "\n",
    "        view(x_input_node.output, :, 1:current_test_batch_size) .= x_batch_test\n",
    "        view(y_label_node.output, :, 1:current_test_batch_size) .= y_batch_test\n",
    "\n",
    "        forward!(order)\n",
    "\n",
    "        predictions = view(model_output_node.output, :, 1:current_test_batch_size)\n",
    "\n",
    "\n",
    "        batch_loss = loss_node.output\n",
    "        \n",
    "        total_test_loss_sum += batch_loss * current_test_batch_size # Sumuj stratę, uwzględniając rozmiar batcha\n",
    "\n",
    "        # --- Oblicz dokładność na bieżącym batchu testowym ---\n",
    "        # Dla klasyfikacji binarnej z progiem 0.5 (lub innym, w zależności od problemu)\n",
    "        batch_accuracy = sum((predictions .> 0.5f0) .== y_batch_test) / current_test_batch_size\n",
    "        total_correct_predictions += batch_accuracy * current_test_batch_size # Sumuj poprawne predykcje\n",
    "    end\n",
    "end\n",
    "\n",
    "# --- Oblicz średnią stratę i średnią dokładność na całym zbiorze testowym ---\n",
    "avg_test_loss = total_test_loss_sum / num_test_samples\n",
    "avg_test_accuracy = total_correct_predictions / num_test_samples * 100.0\n",
    "\n",
    "println(@sprintf(\"Test Loss (czas: %.2fs): %.4f\", t_test, avg_test_loss))\n",
    "println(\"Test Accuracy: $avg_test_accuracy %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
