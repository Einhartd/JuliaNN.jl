{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CNN dla NLP - analiza sekwencji s≈Ç√≥w\n",
    "\n",
    "Ten notebook testuje CNN 1D na analizie prostych sekwencji \"s≈Ç√≥w\" (token√≥w), podobnie jak w Flux do zada≈Ñ NLP. U≈ºywamy bardzo ma≈Çych danych, kt√≥re mo≈ºna policzyƒá rƒôcznie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importowanie modu≈Ç√≥w i bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modu≈Çy za≈Çadowane pomy≈õlnie!\n"
     ]
    }
   ],
   "source": [
    "include(\"../MyReverseDiff.jl\")\n",
    "include(\"../MyEmbedding.jl\")\n",
    "include(\"../MyMlp.jl\")\n",
    "\n",
    "using .MyReverseDiff\n",
    "using .MyEmbedding\n",
    "using .MyMlp\n",
    "using Printf\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "\n",
    "# Ustaw seed dla reprodukowalno≈õci\n",
    "Random.seed!(42)\n",
    "\n",
    "println(\"Modu≈Çy za≈Çadowane pomy≈õlnie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Przygotowanie danych tekstowych\n",
    "\n",
    "Utworzymy mini-s≈Çownik i 2 proste \"zdania\" z r√≥≈ºnymi wzorami sekwencyjnymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S≈Çownik:\n",
      "1: good\n",
      "2: bad\n",
      "3: movie\n",
      "4: very\n",
      "5: <PAD>\n",
      "\n",
      "Parametry:\n",
      "- Rozmiar s≈Çownika: 5\n",
      "- Wymiar embedding: 3\n",
      "- D≈Çugo≈õƒá sekwencji: 4\n"
     ]
    }
   ],
   "source": [
    "# Mini s≈Çownik (bardzo ma≈Çy dla prostoty)\n",
    "vocab = [\"good\", \"bad\", \"movie\", \"very\", \"<PAD>\"]\n",
    "vocab_size = length(vocab)\n",
    "embedding_dim = 3  # Ma≈Çe embedding dla ≈Çatwych oblicze≈Ñ\n",
    "sequence_length = 4  # D≈Çugo≈õƒá sekwencji\n",
    "\n",
    "println(\"S≈Çownik:\")\n",
    "for (i, word) in enumerate(vocab)\n",
    "    println(\"$i: $word\")\n",
    "end\n",
    "\n",
    "println(\"\\nParametry:\")\n",
    "println(\"- Rozmiar s≈Çownika: $vocab_size\")\n",
    "println(\"- Wymiar embedding: $embedding_dim\")\n",
    "println(\"- D≈Çugo≈õƒá sekwencji: $sequence_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sekwencja 1 (pozytywna): [\"very\", \"good\", \"movie\", \"<PAD>\"]\n",
      "Indeksy: Float32[4.0, 1.0, 3.0, 5.0]\n",
      "\n",
      "Sekwencja 2 (negatywna): [\"very\", \"bad\", \"movie\", \"<PAD>\"]\n",
      "Indeksy: Float32[4.0, 2.0, 3.0, 5.0]\n",
      "\n",
      "Shape danych X: (4, 2)\n",
      "Etykiety y: Float32[1.0 0.0]\n",
      "Shape etykiet: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Sekwencje tekstowe jako indeksy\n",
    "# Sekwencja 1: \"very good movie <PAD>\" ‚Üí [5, 2, 4, 1] ‚Üí pozytywna (klasa 1)\n",
    "# Sekwencja 2: \"very bad movie <PAD>\" ‚Üí [5, 3, 4, 1] ‚Üí negatywna (klasa 0)\n",
    "\n",
    "sequence_1 = Float32[4, 1, 3, 5]  # very good movie <PAD>\n",
    "sequence_2 = Float32[4, 2, 3, 5]  # very bad movie <PAD>\n",
    "\n",
    "# Konwertuj na format batch (sequence_length, batch_size)\n",
    "X_batch = zeros(Float32, sequence_length, 2)\n",
    "X_batch[:, 1] = sequence_1\n",
    "X_batch[:, 2] = sequence_2\n",
    "\n",
    "# Etykiety: sekwencja 1 ‚Üí pozytywna (1), sekwencja 2 ‚Üí negatywna (0)\n",
    "y_batch = Float32[1.0 0.0]  # (1, 2) \n",
    "\n",
    "println(\"Sekwencja 1 (pozytywna): \", [vocab[Int(i)] for i in sequence_1])\n",
    "println(\"Indeksy: \", sequence_1)\n",
    "println(\"\\nSekwencja 2 (negatywna): \", [vocab[Int(i)] for i in sequence_2])\n",
    "println(\"Indeksy: \", sequence_2)\n",
    "println(\"\\nShape danych X: \", size(X_batch))\n",
    "println(\"Etykiety y: \", y_batch)\n",
    "println(\"Shape etykiet: \", size(y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definicja modelu CNN dla NLP\n",
    "\n",
    "Architektura podobna do Flux:\n",
    "- **Embedding**: s≈Çowa ‚Üí wektory\n",
    "- **Conv1D**: wykrywa n-gramy (wzory w sekwencjach)\n",
    "- **MaxPool**: wybiera najwa≈ºniejsze cechy\n",
    "- **Flatten**: sp≈Çaszczenie\n",
    "- **Dense**: klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametry modelu NLP:\n",
      "- Embedding: 5 s≈Ç√≥w ‚Üí 3 wymiar√≥w\n",
      "- CNN: 2 filtr√≥w, kernel size 2 (analizuje 2 s≈Çowa naraz)\n",
      "- Warstwa ukryta: 4 neuron√≥w\n",
      "- Wyj≈õcie: 1 neuron (sentiment pozytywny/negatywny)\n",
      "- Batch size: 2\n"
     ]
    }
   ],
   "source": [
    "# Parametry modelu\n",
    "vocab_size = 5\n",
    "embedding_dim = 3\n",
    "conv_filters = 2        # Liczba filtr√≥w CNN\n",
    "kernel_size = 2         # Rozmiar kernela (analizuje 2 kolejne s≈Çowa)\n",
    "hidden_size = 4         # Rozmiar warstwy ukrytej\n",
    "output_size = 1         # Klasyfikacja binarna\n",
    "batch_size = 2\n",
    "\n",
    "println(\"Parametry modelu NLP:\")\n",
    "println(\"- Embedding: $vocab_size s≈Ç√≥w ‚Üí $embedding_dim wymiar√≥w\")\n",
    "println(\"- CNN: $conv_filters filtr√≥w, kernel size $kernel_size (analizuje $kernel_size s≈Çowa naraz)\")\n",
    "println(\"- Warstwa ukryta: $hidden_size neuron√≥w\")\n",
    "println(\"- Wyj≈õcie: $output_size neuron (sentiment pozytywny/negatywny)\")\n",
    "println(\"- Batch size: $batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CNN dla NLP utworzony pomy≈õlnie!\n",
      "Liczba warstw: 6\n",
      "\n",
      "Architektura:\n",
      "1. Embedding: s≈Çowa ‚Üí wektory 3-wymiarowe\n",
      "2. Conv1D: wykrywa wzory w 2 kolejnych s≈Çowach\n",
      "3. MaxPool: wybiera najwa≈ºniejsze cechy\n",
      "4. Flatten: sp≈Çaszczenie do wektora\n",
      "5. Dense: ukryta warstwa z ReLU\n",
      "6. Dense: klasyfikacja z sigmoid\n"
     ]
    }
   ],
   "source": [
    "# Model: Embedding ‚Üí Conv1D ‚Üí Pool ‚Üí Flatten ‚Üí Dense ‚Üí Dense\n",
    "model = Chain(\n",
    "    Embedding(vocab_size, embedding_dim; name=\"embedding\"),\n",
    "    ConvolutionBlock(conv_filters, kernel_size; name=\"conv1d\"),\n",
    "    PoolingBlock(3; name=\"maxpool\"),  # Max pooling\n",
    "    FlattenBlock(name=\"flatten\"),\n",
    "    Dense(8, hidden_size, relu; name=\"hidden\"),\n",
    "    Dense(hidden_size, output_size, œÉ; name=\"output\")\n",
    ")\n",
    "\n",
    "println(\"Model CNN dla NLP utworzony pomy≈õlnie!\")\n",
    "println(\"Liczba warstw: \", length(model.layers))\n",
    "\n",
    "println(\"\\nArchitektura:\")\n",
    "println(\"1. Embedding: s≈Çowa ‚Üí wektory $embedding_dim-wymiarowe\")\n",
    "println(\"2. Conv1D: wykrywa wzory w $kernel_size kolejnych s≈Çowach\")\n",
    "println(\"3. MaxPool: wybiera najwa≈ºniejsze cechy\")\n",
    "println(\"4. Flatten: sp≈Çaszczenie do wektora\")\n",
    "println(\"5. Dense: ukryta warstwa z ReLU\")\n",
    "println(\"6. Dense: klasyfikacja z sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rƒôczne ustawienie wag dla prostoty oblicze≈Ñ\n",
    "\n",
    "Ustawimy proste warto≈õci, kt√≥re pozwolƒÖ na ≈Çatwe obliczenia rƒôczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3√ó5 Matrix{Float32}:\n",
       " 1.0  -1.0  0.5  0.0  0.0\n",
       " 0.5   0.5  0.0  1.0  0.0\n",
       " 1.0  -1.0  1.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding weights (3√ó5 - wymiary √ó s≈Çowa):\n",
      "\n",
      "Interpretacja embedding√≥w:\n",
      "good: Float32[1.0, 0.5, 1.0]\n",
      "bad: Float32[-1.0, 0.5, -1.0]\n",
      "movie: Float32[0.5, 0.0, 1.0]\n",
      "very: Float32[0.0, 1.0, 0.0]\n",
      "<PAD>: Float32[0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Embedding weights - ka≈ºde s≈Çowo ma sw√≥j unikalny wektor\n",
    "embedding_weights = Float32[\n",
    "    1.0  -1.0   0.5  0.0 0.0;   # wymiar 1: <PAD>, good, bad, movie, very\n",
    "    0.5   0.5   0.0  1.0 0.0;   # wymiar 2\n",
    "    1.0  -1.0   1.0  0.0 0.0    # wymiar 3\n",
    "]\n",
    "model.layers[1].W.output = embedding_weights\n",
    "\n",
    "println(\"Embedding weights (3√ó5 - wymiary √ó s≈Çowa):\")\n",
    "display(embedding_weights)\n",
    "println(\"\\nInterpretacja embedding√≥w:\")\n",
    "for (i, word) in enumerate(vocab)\n",
    "    vec = embedding_weights[:, i]\n",
    "    println(\"$word: $vec\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2√ó2 Matrix{Float32}:\n",
       "  1.0  0.0\n",
       " -1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtry konwolucyjne (kernel_size√ónum_filters = 2√ó2):\n",
      "\n",
      "Filtr 1: [1.0, -1.0] - wykrywa pozytywne trendy\n",
      "Filtr 2: [0.0, 1.0] - wykrywa drugie s≈Çowo w parze\n"
     ]
    }
   ],
   "source": [
    "# Filtry konwolucyjne - wykrywajƒÖ r√≥≈ºne wzory 2-gram√≥w\n",
    "conv_weights = Float32[\n",
    "    1.0   0.0;    # Filtr 1: wykrywa pozytywne przej≈õcia\n",
    "    -1.0  1.0     # Filtr 2: wykrywa negatywne wzory\n",
    "]\n",
    "model.layers[2].masks.output = conv_weights\n",
    "\n",
    "println(\"Filtry konwolucyjne (kernel_size√ónum_filters = 2√ó2):\")\n",
    "display(conv_weights)\n",
    "println(\"\\nFiltr 1: [1.0, -1.0] - wykrywa pozytywne trendy\")\n",
    "println(\"Filtr 2: [0.0, 1.0] - wykrywa drugie s≈Çowo w parze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó8 Matrix{Float32}:\n",
       "  1.0   0.5  -0.5   1.0   0.5  -0.5  -0.5   1.0\n",
       "  0.5   1.0   1.0   0.5   1.0   1.0   1.0   0.5\n",
       " -0.5   0.0   1.0  -0.5   0.0   1.0   1.0  -0.5\n",
       "  1.0  -1.0   0.5   1.0  -1.0   0.5   0.5   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1√ó4 Matrix{Float32}:\n",
       " 0.5  -0.5  1.0  -1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wagi warstwy ukrytej (4√ó3):\n",
      "\n",
      "Wagi warstwy wyj≈õciowej (1√ó4):\n"
     ]
    }
   ],
   "source": [
    "# Wagi Dense layers\n",
    "model.layers[5].W.output = Float32[  # hidden layer weights (4√ó8)\n",
    "    1.0   0.5  -0.5  1.0   0.5  -0.5  -0.5  1.0 ;\n",
    "    0.5   1.0   1.0  0.5   1.0   1.0  1.0  0.5;\n",
    "    -0.5  0.0   1.0  -0.5  0.0   1.0  1.0  -0.5;\n",
    "    1.0  -1.0   0.5  1.0  -1.0   0.5  0.5  1.0\n",
    "]\n",
    "\n",
    "bias_vector = Float32[0.0; 0.0; 0.0; 0.0]\n",
    "bias_matrix = reshape(bias_vector, 4, 1)\n",
    "model.layers[5].b.output = bias_matrix\n",
    "\n",
    "bias_vector = Float32[0.5 -0.5 1.0 -1.0]\n",
    "bias_matrix = reshape(bias_vector, 1, 4)\n",
    "model.layers[6].W.output = bias_matrix\n",
    "\n",
    "bias_vector = Float32[0.0]\n",
    "bias_matrix = reshape(bias_vector, 1, 1)\n",
    "model.layers[6].b.output = bias_matrix\n",
    "\n",
    "println(\"Wagi warstwy ukrytej (4√ó3):\")\n",
    "display(model.layers[5].W.output)\n",
    "println(\"\\nWagi warstwy wyj≈õciowej (1√ó4):\")\n",
    "display(model.layers[6].W.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Budowanie grafu obliczeniowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó2 Matrix{Float32}:\n",
       " 4.0  4.0\n",
       " 1.0  2.0\n",
       " 3.0  3.0\n",
       " 5.0  5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1√ó2 Matrix{Float32}:\n",
       " 1.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane wej≈õciowe ustawione:\n",
      "Shape sekwencji X: (4, 2)\n",
      "Shape etykiet y: (1, 2)\n",
      "\n",
      "Sekwencje jako indeksy:\n",
      "\n",
      "Etykiety:\n"
     ]
    }
   ],
   "source": [
    "# Utworzenie wƒôz≈Ç√≥w wej≈õciowych\n",
    "x_input_node = Constant(zeros(Float32, sequence_length, batch_size))\n",
    "y_label_node = Constant(zeros(Float32, output_size, batch_size))\n",
    "\n",
    "# Ustaw dane wej≈õciowe\n",
    "x_input_node.output = X_batch\n",
    "y_label_node.output = y_batch\n",
    "\n",
    "println(\"Dane wej≈õciowe ustawione:\")\n",
    "println(\"Shape sekwencji X: \", size(x_input_node.output))\n",
    "println(\"Shape etykiet y: \", size(y_label_node.output))\n",
    "println(\"\\nSekwencje jako indeksy:\")\n",
    "display(x_input_node.output)\n",
    "println(\"\\nEtykiety:\")\n",
    "display(y_label_node.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graf obliczeniowy zbudowany pomy≈õlnie!\n",
      "Liczba wƒôz≈Ç√≥w w grafie: 20\n",
      "Typ wƒôz≈Ça loss: ScalarOperator{typeof(Main.MyReverseDiff.binary_cross_entropy_loss_impl)}\n",
      "Typ wƒôz≈Ça output: BroadcastedOperator{typeof(œÉ)}\n"
     ]
    }
   ],
   "source": [
    "# Zbuduj graf obliczeniowy\n",
    "loss_node, model_output_node, order = build_graph!(model, binarycrossentropy, x_input_node, y_label_node; loss_name=\"loss\")\n",
    "\n",
    "println(\"Graf obliczeniowy zbudowany pomy≈õlnie!\")\n",
    "println(\"Liczba wƒôz≈Ç√≥w w grafie: \", length(order))\n",
    "println(\"Typ wƒôz≈Ça loss: \", typeof(loss_node))\n",
    "println(\"Typ wƒôz≈Ça output: \", typeof(model_output_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Forward Pass - analiza krok po kroku\n",
    "\n",
    "Przeanalizujemy jak model przetwarza sekwencje s≈Ç√≥w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DANE WEJ≈öCIOWE - SEKWENCJE S≈Å√ìW ===\n",
      "\n",
      "Sekwencja 1 (pozytywna):\n",
      "S≈Çowa: [\"very\", \"good\", \"movie\", \"<PAD>\"]\n",
      "Indeksy: Float32[4.0, 1.0, 3.0, 5.0]\n",
      "\n",
      "Sekwencja 2 (negatywna):\n",
      "S≈Çowa: [\"very\", \"bad\", \"movie\", \"<PAD>\"]\n",
      "Indeksy: Float32[4.0, 2.0, 3.0, 5.0]\n",
      "\n",
      "Zadanie: Klasyfikuj sentiment (pozytywny=1, negatywny=0)\n"
     ]
    }
   ],
   "source": [
    "println(\"=== DANE WEJ≈öCIOWE - SEKWENCJE S≈Å√ìW ===\")\n",
    "println(\"\\nSekwencja 1 (pozytywna):\")\n",
    "seq1_words = [vocab[Int(i)] for i in X_batch[:, 1]]\n",
    "seq1_indices = X_batch[:, 1]\n",
    "println(\"S≈Çowa: \", seq1_words)\n",
    "println(\"Indeksy: \", seq1_indices)\n",
    "\n",
    "println(\"\\nSekwencja 2 (negatywna):\")\n",
    "seq2_words = [vocab[Int(i)] for i in X_batch[:, 2]]\n",
    "seq2_indices = X_batch[:, 2]\n",
    "println(\"S≈Çowa: \", seq2_words)\n",
    "println(\"Indeksy: \", seq2_indices)\n",
    "\n",
    "println(\"\\nZadanie: Klasyfikuj sentiment (pozytywny=1, negatywny=0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FORWARD PASS ===\n",
      "Wykonujƒô forward pass...\n",
      "Forward pass zako≈Ñczony pomy≈õlnie!\n",
      "\n",
      "Warto≈õƒá loss: 0.7750082\n"
     ]
    }
   ],
   "source": [
    "# Wykonaj forward pass\n",
    "println(\"=== FORWARD PASS ===\")\n",
    "println(\"Wykonujƒô forward pass...\")\n",
    "forward_result = forward!(order)\n",
    "println(\"Forward pass zako≈Ñczony pomy≈õlnie!\")\n",
    "println(\"\\nWarto≈õƒá loss: \", loss_node.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WYNIKI KLASYFIKACJI SENTIMENTU ===\n",
      "\n",
      "Predykcje modelu: Float32[0.37754068 0.4378235]\n",
      "Prawdziwe etykiety: Float32[1.0 0.0]\n",
      "Binary Cross Entropy Loss: 0.7750082\n",
      "\n",
      "=== INTERPRETACJA WYNIK√ìW ===\n",
      "\n",
      "Sekwencja 1: very good movie <PAD>\n",
      "  Predykcja: 0.3775 ‚Üí NEGATYWNY\n",
      "  Prawda: POZYTYWNY ‚úó\n",
      "\n",
      "Sekwencja 2: very bad movie <PAD>\n",
      "  Predykcja: 0.4378 ‚Üí NEGATYWNY\n",
      "  Prawda: NEGATYWNY ‚úì\n"
     ]
    }
   ],
   "source": [
    "println(\"=== WYNIKI KLASYFIKACJI SENTIMENTU ===\")\n",
    "println(\"\\nPredykcje modelu: \", model_output_node.output)\n",
    "println(\"Prawdziwe etykiety: \", y_label_node.output)\n",
    "println(\"Binary Cross Entropy Loss: \", loss_node.output)\n",
    "\n",
    "# Interpretacja wynik√≥w\n",
    "predictions = model_output_node.output\n",
    "labels = y_label_node.output\n",
    "\n",
    "println(\"\\n=== INTERPRETACJA WYNIK√ìW ===\")\n",
    "for i in 1:batch_size\n",
    "    words = [vocab[Int(j)] for j in X_batch[:, i]]\n",
    "    pred_prob = round(predictions[1, i], digits=4)\n",
    "    pred_class = pred_prob > 0.5 ? \"POZYTYWNY\" : \"NEGATYWNY\"\n",
    "    true_class = Int(labels[1, i]) == 1 ? \"POZYTYWNY\" : \"NEGATYWNY\"\n",
    "    correct = (pred_prob > 0.5) == (labels[1, i] == 1.0) ? \"‚úì\" : \"‚úó\"\n",
    "    \n",
    "    println(\"\\nSekwencja $i: $(join(words, \" \"))\")\n",
    "    println(\"  Predykcja: $pred_prob ‚Üí $pred_class\")\n",
    "    println(\"  Prawda: $true_class $correct\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Weryfikacja rƒôczna - obliczenia embedding i konwolucji\n",
    "\n",
    "Policzymy rƒôcznie pierwsze kroki, ≈ºeby zrozumieƒá jak CNN analizuje tekst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3√ó5 Matrix{Float32}:\n",
       " 1.0  -1.0  0.5  0.0  0.0\n",
       " 0.5   0.5  0.0  1.0  0.0\n",
       " 1.0  -1.0  1.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3√ó4 Matrix{Float32}:\n",
       " 0.0  -1.0  0.0  1.0\n",
       " 0.0   0.5  1.0  0.5\n",
       " 0.0  -1.0  0.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WERYFIKACJA RƒòCZNA - EMBEDDING ===\n",
      "\n",
      "Embedding weights:\n",
      "\n",
      "1. EMBEDDING SEKWENCJI 1: 'very good movie <PAD>'\n",
      "Indeksy: [5, 2, 4, 1]\n",
      "\n",
      "Slowo 'very' (indeks 5):\n",
      "Embedding: Float32[0.0, 0.0, 0.0]\n",
      "\n",
      "Slowo 'good' (indeks 2):\n",
      "Embedding: Float32[-1.0, 0.5, -1.0]\n",
      "\n",
      "Slowo 'movie' (indeks 4):\n",
      "Embedding: Float32[0.0, 1.0, 0.0]\n",
      "\n",
      "Slowo '<PAD>' (indeks 1):\n",
      "Embedding: Float32[1.0, 0.5, 1.0]\n",
      "\n",
      "Embedded sekwencja 1 (3√ó4 - embedding_dim √ó sequence_length):\n"
     ]
    }
   ],
   "source": [
    "println(\"=== WERYFIKACJA RƒòCZNA - EMBEDDING ===\")\n",
    "println(\"\\nEmbedding weights:\")\n",
    "display(embedding_weights)\n",
    "\n",
    "println(\"\\n1. EMBEDDING SEKWENCJI 1: 'very good movie <PAD>'\")\n",
    "println(\"Indeksy: [5, 2, 4, 1]\")\n",
    "\n",
    "println(\"\\nSlowo 'very' (indeks 5):\")\n",
    "very_embedding = embedding_weights[:, 5]\n",
    "println(\"Embedding: \", very_embedding)\n",
    "\n",
    "println(\"\\nSlowo 'good' (indeks 2):\")\n",
    "good_embedding = embedding_weights[:, 2]\n",
    "println(\"Embedding: \", good_embedding)\n",
    "\n",
    "println(\"\\nSlowo 'movie' (indeks 4):\")\n",
    "movie_embedding = embedding_weights[:, 4]\n",
    "println(\"Embedding: \", movie_embedding)\n",
    "\n",
    "println(\"\\nSlowo '<PAD>' (indeks 1):\")\n",
    "pad_embedding = embedding_weights[:, 1]\n",
    "println(\"Embedding: \", pad_embedding)\n",
    "\n",
    "println(\"\\nEmbedded sekwencja 1 (3√ó4 - embedding_dim √ó sequence_length):\")\n",
    "embedded_seq1 = hcat(very_embedding, good_embedding, movie_embedding, pad_embedding)\n",
    "display(embedded_seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2√ó2 Matrix{Float32}:\n",
       "  1.0  0.0\n",
       " -1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. KONWOLUCJA 1D - WYKRYWANIE N-GRAM√ìW\n",
      "\n",
      "Filtry konwolucyjne (kernel size 2):\n",
      "Filtr 1: [1.0, -1.0] - wykrywa wzory pozytywne\n",
      "Filtr 2: [0.0, 1.0] - skupia siƒô na drugim s≈Çowie w parze\n",
      "\n",
      "Konwolucja analizuje pary s≈Ç√≥w:\n",
      "- Para 1: 'very' + 'good'\n",
      "- Para 2: 'good' + 'movie'\n",
      "- Para 3: 'movie' + '<PAD>'\n",
      "\n",
      "Przyk≈Çad obliczenia dla pary 'very' + 'good':\n",
      "Very embedding: Float32[0.0, 0.0, 0.0]\n",
      "Good embedding: Float32[-1.0, 0.5, -1.0]\n",
      "\n",
      "Filtr 1 [1.0, -1.0] na wymiarze 1:\n",
      "1.0 √ó 0.0 + (-1.0) √ó 1.0 = -1.0\n",
      "\n",
      "Filtr 2 [0.0, 1.0] na wymiarze 1:\n",
      "0.0 √ó 0.0 + 1.0 √ó 1.0 = 1.0\n",
      "\n",
      "To pokazuje jak CNN wykrywa r√≥≈ºnice miƒôdzy 'very good' a 'very bad'!\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n2. KONWOLUCJA 1D - WYKRYWANIE N-GRAM√ìW\")\n",
    "println(\"\\nFiltry konwolucyjne (kernel size 2):\")\n",
    "display(conv_weights)\n",
    "println(\"Filtr 1: [1.0, -1.0] - wykrywa wzory pozytywne\")\n",
    "println(\"Filtr 2: [0.0, 1.0] - skupia siƒô na drugim s≈Çowie w parze\")\n",
    "\n",
    "println(\"\\nKonwolucja analizuje pary s≈Ç√≥w:\")\n",
    "println(\"- Para 1: 'very' + 'good'\")\n",
    "println(\"- Para 2: 'good' + 'movie'\")\n",
    "println(\"- Para 3: 'movie' + '<PAD>'\")\n",
    "\n",
    "println(\"\\nPrzyk≈Çad obliczenia dla pary 'very' + 'good':\")\n",
    "println(\"Very embedding: \", very_embedding)\n",
    "println(\"Good embedding: \", good_embedding)\n",
    "println(\"\\nFiltr 1 [1.0, -1.0] na wymiarze 1:\")\n",
    "println(\"1.0 √ó 0.0 + (-1.0) √ó 1.0 = -1.0\")\n",
    "println(\"\\nFiltr 2 [0.0, 1.0] na wymiarze 1:\")\n",
    "println(\"0.0 √ó 0.0 + 1.0 √ó 1.0 = 1.0\")\n",
    "\n",
    "println(\"\\nTo pokazuje jak CNN wykrywa r√≥≈ºnice miƒôdzy 'very good' a 'very bad'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Backward Pass - uczenie siƒô wzor√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BACKWARD PASS - UCZENIE SIƒò ===\n",
      "Wykonujƒô backward pass...\n",
      "Backward pass zako≈Ñczony!\n",
      "\n",
      "=== OBLICZONE GRADIENTY ===\n",
      "\n",
      "1. Gradienty embedding√≥w (kt√≥re s≈Çowa potrzebujƒÖ poprawy):\n",
      "\n",
      "2. Gradienty filtr√≥w konwolucyjnych (kt√≥re wzory poprawiƒá):\n",
      "\n",
      "3. Gradienty warstwy klasyfikacyjnej:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3√ó5 Matrix{Float32}:\n",
       " 0.0         0.0        -0.28815     0.0       0.0\n",
       " 0.389037   -0.0547279   0.342878    0.334309  0.0\n",
       " 0.0778074   0.0547279   0.0778074  -0.389037  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2√ó2 Matrix{Float32}:\n",
       " 0.711806   0.15133\n",
       " 0.0547279  0.548936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1√ó4 Matrix{Float32}:\n",
       " 0.0632969  -0.507748  -0.340251  -0.155615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"=== BACKWARD PASS - UCZENIE SIƒò ===\")\n",
    "println(\"Wykonujƒô backward pass...\")\n",
    "\n",
    "# Wykonaj backward pass\n",
    "backward!(order)\n",
    "println(\"Backward pass zako≈Ñczony!\")\n",
    "\n",
    "println(\"\\n=== OBLICZONE GRADIENTY ===\")\n",
    "\n",
    "println(\"\\n1. Gradienty embedding√≥w (kt√≥re s≈Çowa potrzebujƒÖ poprawy):\")\n",
    "embedding_grads = model.layers[1].W.gradient\n",
    "display(embedding_grads)\n",
    "\n",
    "println(\"\\n2. Gradienty filtr√≥w konwolucyjnych (kt√≥re wzory poprawiƒá):\")\n",
    "conv_grads = model.layers[2].masks.gradient\n",
    "display(conv_grads)\n",
    "\n",
    "println(\"\\n3. Gradienty warstwy klasyfikacyjnej:\")\n",
    "output_grads = model.layers[6].W.gradient\n",
    "display(output_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1√ó8√ó2 Array{Float64, 3}:\n",
       "[:, :, 1] =\n",
       " 0.389037  -0.233422  0.0778074  0.389037  ‚Ä¶  0.0778074  0.0778074  0.389037\n",
       "\n",
       "[:, :, 2] =\n",
       " -0.0547279  -0.0547279  0.0547279  ‚Ä¶  0.0547279  0.0547279  -0.0547279"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = [0.38903707 -0.054727938; -0.23342223 -0.054727938; 0.07780741 0.05472794; 0.38903707 -0.054727938; -0.23342223 -0.054727938; 0.07780741 0.05472794; 0.07780741 0.05472794; 0.38903707 -0.054727938]\n",
    "reshape(a,(1,8,2)...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Podsumowanie i por√≥wnanie z Flux\n",
    "\n",
    "Analiza jak nasza implementacja por√≥wnuje siƒô z profesjonalnymi bibliotekami NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PODSUMOWANIE TESTU CNN DLA NLP ===\n",
      "\n",
      "‚úì Zadanie: Klasyfikacja sentimentu tekstu\n",
      "‚úì Dane: 2 sekwencje po 4 s≈Çowa\n",
      "‚úì Model: Embedding ‚Üí Conv1D ‚Üí Pool ‚Üí Dense\n",
      "‚úì Forward pass: wykonany\n",
      "‚úì Backward pass: wykonany\n",
      "‚úì Loss: 0.775008\n",
      "\n",
      "üìä Wyniki klasyfikacji sentimentu:\n",
      "  'very good movie <PAD>': 0.3775 ‚Üí NEGATYWNY (cel: POZYTYWNY)\n",
      "  'very bad movie <PAD>': 0.4378 ‚Üí NEGATYWNY (cel: NEGATYWNY)\n",
      "\n",
      "üîç Podobie≈Ñstwa z Flux CNN:\n",
      "  ‚úì Embedding layer - s≈Çowa na wektory\n",
      "  ‚úì Conv1D - wykrywanie n-gram√≥w\n",
      "  ‚úì MaxPooling - selekcja najwa≈ºniejszych cech\n",
      "  ‚úì Dense - klasyfikacja finalna\n",
      "\n",
      "üéØ Zastosowania:\n",
      "  - Analiza sentimentu (pozytywny/negatywny)\n",
      "  - Klasyfikacja tematyczna tekst√≥w\n",
      "  - Wykrywanie spamu\n",
      "  - Analiza emocji w social media\n",
      "\n",
      "üí° Kluczowe koncepty:\n",
      "  - N-gramy: CNN wykrywa wzory w parach/tr√≥jkach s≈Ç√≥w\n",
      "  - Embeddingi: przekszta≈ÇcajƒÖ s≈Çowa w wektory liczb\n",
      "  - Pooling: wybiera najwa≈ºniejsze cechy z ca≈Çego tekstu\n",
      "  - End-to-end learning: ca≈Çy model uczy siƒô razem\n"
     ]
    }
   ],
   "source": [
    "println(\"=== PODSUMOWANIE TESTU CNN DLA NLP ===\")\n",
    "\n",
    "println(\"\\n‚úì Zadanie: Klasyfikacja sentimentu tekstu\")\n",
    "println(\"‚úì Dane: 2 sekwencje po 4 s≈Çowa\")\n",
    "println(\"‚úì Model: Embedding ‚Üí Conv1D ‚Üí Pool ‚Üí Dense\")\n",
    "println(\"‚úì Forward pass: wykonany\")\n",
    "println(\"‚úì Backward pass: wykonany\")\n",
    "println(\"‚úì Loss: \", round(loss_node.output, digits=6))\n",
    "\n",
    "println(\"\\nüìä Wyniki klasyfikacji sentimentu:\")\n",
    "for i in 1:batch_size\n",
    "    words = [vocab[Int(j)] for j in X_batch[:, i]]\n",
    "    pred = round(model_output_node.output[1, i], digits=4)\n",
    "    sentiment = pred > 0.5 ? \"POZYTYWNY\" : \"NEGATYWNY\"\n",
    "    true_label = Int(y_label_node.output[1, i]) == 1 ? \"POZYTYWNY\" : \"NEGATYWNY\"\n",
    "    println(\"  '$(join(words, \" \"))': $pred ‚Üí $sentiment (cel: $true_label)\")\n",
    "end\n",
    "\n",
    "println(\"\\nüîç Podobie≈Ñstwa z Flux CNN:\")\n",
    "println(\"  ‚úì Embedding layer - s≈Çowa na wektory\")\n",
    "println(\"  ‚úì Conv1D - wykrywanie n-gram√≥w\")\n",
    "println(\"  ‚úì MaxPooling - selekcja najwa≈ºniejszych cech\")\n",
    "println(\"  ‚úì Dense - klasyfikacja finalna\")\n",
    "\n",
    "println(\"\\nüéØ Zastosowania:\")\n",
    "println(\"  - Analiza sentimentu (pozytywny/negatywny)\")\n",
    "println(\"  - Klasyfikacja tematyczna tekst√≥w\")\n",
    "println(\"  - Wykrywanie spamu\")\n",
    "println(\"  - Analiza emocji w social media\")\n",
    "\n",
    "println(\"\\nüí° Kluczowe koncepty:\")\n",
    "println(\"  - N-gramy: CNN wykrywa wzory w parach/tr√≥jkach s≈Ç√≥w\")\n",
    "println(\"  - Embeddingi: przekszta≈ÇcajƒÖ s≈Çowa w wektory liczb\")\n",
    "println(\"  - Pooling: wybiera najwa≈ºniejsze cechy z ca≈Çego tekstu\")\n",
    "println(\"  - End-to-end learning: ca≈Çy model uczy siƒô razem\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
